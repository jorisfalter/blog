<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
  <meta charset="utf-8">
  <title>Joris' Homepage</title>
  <meta name="viewport" content="width=device-width" , initial-scale=1 />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@400;600;700&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
  <script src="jquery.js"></script>
  <script>
    $(function () {
      $("#includedContent").load("headerNavBar.html");
    });
  </script>
</head>


<body>

  <div id="includedContent"></div>

  <div class="container">

    <div class="date">29 Oct 2025</div>
    <div class="content">
      <h1>Your Job Is Safe</h1>

      <p>I recently had to do an integration between a Chinese robot and a fleet management platform.</p>

      <p>There was some time pressure so I started vibe coding it: I shared the pdfs and links to the documentation
        of
        both platforms to Cursor and
        Chatgpt and told them to figure it out.</p>

      <p>Big Mistake</p>

      <p>I spent 10+ hours trial and erroring, clicking <em>run</em> in Cursor or saying <em>yes</em> when it suggested
        changes.
        Without me doing any effort to
        understand what it was doing. Iterating error after error towards a solution.</p>

      <p>Turns out, Cursor didn't know what it was doing as well.</p>

      <p>The documentation and instructions were quite poor, for both platforms, and it turns out that the adagio
        <em>garbage in garbage out</em> also applies to LLMs.
      </p>

      <p>But I didn't know that at the time.</p>

      <p>Desperate I continued clicking, intimidated by the time pressure, and the size of the code base.</p>

      <p>Slowly I developed a 6th sense, when the LLM was trying to bullshit its way through, and leading me down
        irrelevant paths.</p>

      <p>In the beginning it only dawned on me after I pressed <em>accept</em> in cursor, but I learned to recognise it
        earlier
        and earlier.</p>

      <p>Now I have half-ass code, half of which I understand, the majority of which I don't.</p>

      <p>And that would be ok if this was the end. But I have to keep building on it.</p>

      <p>And with every new step I have to implement, I realise how poorly I understand what it does, and how I need to
        spend extra time understanding where I'm at.</p>




      <p>This isn't a call to write bad documentation (though there will always be bad documentation, just like there
        will always be bad companies).</p>

      <p>It's a call to use LLMs in a smart way. They can help understand codebases faster, they can help figure out
        documentation faster, and sometimes - just sometimes - the shortcut works and it wings it.</p>

      <p>But I wouldn't count on it.</p>

      <p>I learned to let the LLM guide me, but not to let it steer me.</p>
      <p>Especially when the LLM is as clueless as me. With that difference that it doesn't admit it.</p>

      <p>Even with good documentation, processes like AWS which are extensively documented on millions of pages, it's
        still important to understand what the underlying code is doing.</p>

      <p>I don't need to understand how eelctricty works to turn on a light switch. But we're not at that point yet.
        Maybe in a distant future, our tasks will be to be architects, to decide what we want, how we want it, and
        describe that in detail and let the LLM run with it</p>

      <p>Writing your ideas down, and someone else executes them. Isn't that what we all want?</p>

      <p>But for now, I believe your engineering job is safe</p>



    </div>

  </div>
  <div class="footer-padding"></div>
  <div class="footer">
    <p>Learned with ❤️ from The App Brewery</p>
  </div>
  </div>
</body>

</html>